# -*- coding: utf-8 -*-
"""Calrories.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kf3mmuPMVcjaqZ1dB_KPGVZBfZFY-5Gu

Install all the required dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV
import joblib

"""Data Collection"""

#loading the data -> pandas DataFrame
calories_data= pd.read_csv('datafull.csv')

#print the data after the combination
calories_data.head()

#some information about the dataset
calories_data.info()

#Check if we have missing values
calories_data.isnull().sum()

correlation = calories_data.corr(numeric_only=True)

#Convert the Text data to numerical values
calories_data.replace({"Gender":{'male':0,'female':1}} , inplace=True)

calories_data.head()

"""Separating features and target"""

# Interaction term: Weight * Duration
calories_data['Weight_Duration_Interaction'] = calories_data['Weight'] * calories_data['Duration']

features_to_use = ['Gender', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Weight_Duration_Interaction']
X = calories_data[features_to_use]
Y = calories_data['Calories']

"""
Feature engineering
Split the data training and test
"""

X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

print(X)

print(Y)


"""
Model Training
"""

# Hyperparameter grid
param_grid = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2', None]  # Adjusted to valid options
}

# Decision Tree model with hyperparameter tuning
decision_tree_model = DecisionTreeRegressor()
grid_search = GridSearchCV(decision_tree_model, param_grid, cv=5, scoring='neg_mean_squared_error')
grid_search.fit(X_train, Y_train)

# Get the best model from the search
best_decision_tree_model = grid_search.best_estimator_

# Use the best model for predictions
dt_pred_tuned = best_decision_tree_model.predict(X_test)
dt_rmse_tuned = np.sqrt(mean_squared_error(Y_test, dt_pred_tuned))

# Perform 5-fold cross-validation for the tuned Decision Tree Model
dt_cv_scores_tuned = cross_val_score(best_decision_tree_model, X, Y, cv=5, scoring='neg_mean_squared_error')
dt_cv_rmse_scores_tuned = np.sqrt(-dt_cv_scores_tuned)

# Feature Importance Plot for Tuned Decision Tree
feature_importance_tuned = pd.DataFrame({'Feature': X.columns, 'Importance': best_decision_tree_model.feature_importances_})
feature_importance_tuned = feature_importance_tuned.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_tuned, palette='viridis')
plt.title('Tuned Decision Tree: Feature Importance')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()

"""
Evaluation of Mean Absolute Error and some data processing
"""

# Evaluation Metrics for Tuned Decision Tree
dt_mae_tuned = mean_absolute_error(Y_test, dt_pred_tuned)
dt_mse_tuned = mean_squared_error(Y_test, dt_pred_tuned)
dt_rmse_tuned = np.sqrt(dt_mse_tuned)
dt_r2_tuned = r2_score(Y_test, dt_pred_tuned)

# Print Results for Tuned Decision Tree
print("\nTuned Decision Tree Metrics:")
print("Mean Absolute Error:", dt_mae_tuned)
print("Mean Squared Error:", dt_mse_tuned)
print("Root Mean Squared Error:", dt_rmse_tuned)
print("R-squared:", dt_r2_tuned)


"""
Model Training: Untuned Decision Tree
"""

# Create and train the untuned Decision Tree model
untuned_decision_tree_model = DecisionTreeRegressor()
untuned_decision_tree_model.fit(X_train, Y_train)
untuned_dt_pred = untuned_decision_tree_model.predict(X_test)

# Evaluate the untuned model on the test set
untuned_dt_mae = mean_absolute_error(Y_test, untuned_dt_pred)
untuned_dt_mse = mean_squared_error(Y_test, untuned_dt_pred)
untuned_dt_rmse = np.sqrt(untuned_dt_mse)
untuned_dt_r2 = r2_score(Y_test, untuned_dt_pred)

# Print Metrics for Untuned Decision Tree
print("\nUntuned Decision Tree Metrics:")
print("Mean Absolute Error:", untuned_dt_mae)
print("Mean Squared Error:", untuned_dt_mse)
print("Root Mean Squared Error:", untuned_dt_rmse)
print("R-squared:", untuned_dt_r2)

# Save the untuned model to a file
joblib.dump(untuned_decision_tree_model, 'calories_untuned_model.pkl')

# Compare Metrics between Tuned and Untuned Decision Tree
print("\nComparison of Tuned and Untuned Decision Tree Models:")
print("Tuned Decision Tree RMSE:", dt_rmse_tuned)
print("Untuned Decision Tree RMSE:", untuned_dt_rmse)

# Save the tuned model to a file
joblib.dump(best_decision_tree_model, 'calories_tuned_model.pkl')

# Scatter plot of Duration vs. Calories with the model predictions

# Assuming 'Duration' is one of the features in X_test
# If 'Duration' is not present, please replace it with the correct feature name
durations = X_test['Duration']

# Predict calories for the given durations using the tuned model
predictions_tuned = best_decision_tree_model.predict(X_test)

# Create a DataFrame with 'Duration' and 'Predictions'
results_df_tuned = pd.DataFrame({'Duration': durations, 'Predicted Calories': predictions_tuned})

# Sort by 'Duration' for a smoother line plot
results_df_tuned.sort_values('Duration', inplace=True)


class CaloriePredictorModel:
    def __init__(self):
        # Load the model here
        self.model = joblib.load('calories_tuned_model.pkl')

    def predict(self, input_data):
        # Convert input_data to a DataFrame
        # Ensure the column names and order match those expected by the model
        df = pd.DataFrame([input_data], columns=['Gender', 'Height', 'Weight', 'Duration', 'Heart_Rate'])  # Add other necessary columns

        # If your model uses any derived or interaction features (like 'Weight_Duration_Interaction'), compute them here
        df['Weight_Duration_Interaction'] = df['Weight'] * df['Duration']

        # Perform prediction
        result = self.model.predict(df)
        return result[0]  # Assuming the result is a single value

    def get_plotting_data(self):
        # Assuming 'durations', 'Y_test', and 'results_df_tuned' are available here
        return durations, Y_test, results_df_tuned


# Scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(durations, Y_test, label='Actual Calories', alpha=0.5)
plt.plot(results_df_tuned['Duration'], results_df_tuned['Predicted Calories'], label='Predicted Calories', color='red', linewidth=2)
plt.title('Actual vs. Predicted Calories Over Duration')
plt.xlabel('Duration')
plt.ylabel('Calories')
plt.legend()
plt.grid(True)
plt.show()
